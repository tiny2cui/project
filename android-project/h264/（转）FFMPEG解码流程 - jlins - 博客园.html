<!DOCTYPE html>
<html lang="zh-cn">
<head>
<meta charset="utf-8"/>
<title>（转）FFMPEG解码流程 - jlins - 博客园</title>
<link type="text/css" rel="stylesheet" href="/bundles/blog-common.css?v=iQQnf2q8V83bi9LbN6IvkHJyxj8GLI9A8HLPvxO-IBQ1"/>
<link id="MainCss" type="text/css" rel="stylesheet" href="http://common.cnblogs.com/Skins/ThinkInside/style.css?id=20140415"/>
<link title="RSS" type="application/rss+xml" rel="alternate" href="http://www.cnblogs.com/dyllove98/rss"/>
<link title="RSD" type="application/rsd+xml" rel="EditURI" href="http://www.cnblogs.com/dyllove98/rsd.xml"/>
<link type="application/wlwmanifest+xml" rel="wlwmanifest" href="http://www.cnblogs.com/dyllove98/wlwmanifest.xml"/>
<script src="http://common.cnblogs.com/script/jquery.js" type="text/javascript"></script>  
<script type="text/javascript">var currentBlogApp = 'dyllove98', cb_enable_mathjax=false;</script>
<script src="/bundles/blog-common.js?v=15gzXd7pJ_PNpSlGpVykf0EBaNg79HWL7oD5vVw0NGA1" type="text/javascript"></script>
</head>
<body>
<a name="top"></a>
<!--PageBeginHtml Block Begin-->
<div align=center>

</div>
<!--PageBeginHtml Block End-->

<!--done-->
<div id="home">
<div id="header">
	<div id="blogTitle">
	<a id="lnkBlogLogo" href="http://www.cnblogs.com/dyllove98/"><img id="blogLogo" src="/Skins/custom/images/logo.gif" alt="返回主页" /></a>			
		
<!--done-->
<h1><a id="Header1_HeaderTitle" class="headermaintitle" href="http://www.cnblogs.com/dyllove98/">水漫金山</a></h1>
<h2></h2>



		
	</div><!--end: blogTitle 博客的标题和副标题 -->
	<div id="navigator">
		
<ul id="navList">
<li><a id="MyLinks1_HomeLink" class="menu" href="http://www.cnblogs.com/">博客园</a></li>
<li><a id="MyLinks1_MyHomeLink" class="menu" href="http://www.cnblogs.com/dyllove98/">首页</a></li>
<li><a class="menu" href="http://q.cnblogs.com/">博问</a></li>
<li><a class="menu" href="http://home.cnblogs.com/ing/">闪存</a></li>
<li><a id="MyLinks1_NewPostLink" class="menu" rel="nofollow" href="http://i.cnblogs.com/EditPosts.aspx?opt=1">新随笔</a></li>
<li><a id="MyLinks1_ContactLink" class="menu" rel="nofollow" href="http://space.cnblogs.com/msg/send/jlins">联系</a></li>
<li><a id="MyLinks1_Syndication" class="menu" href="http://www.cnblogs.com/dyllove98/rss">订阅</a>
<!--<a id="MyLinks1_XMLLink" class="aHeaderXML" href="http://www.cnblogs.com/dyllove98/rss"><img src="http://www.cnblogs.com/images/xml.gif" alt="订阅" /></a>--></li>
<li><a id="MyLinks1_Admin" class="menu" rel="nofollow" href="http://i.cnblogs.com/">管理</a></li>
</ul>
		<div class="blogStats">
			
			
<!--done-->
随笔- 3262&nbsp;
文章- 0&nbsp;
评论- 129&nbsp;

			
		</div><!--end: blogStats -->
	</div><!--end: navigator 博客导航栏 -->
</div><!--end: header 头部 -->

<div id="main">
	<div id="mainContent">
	<div class="forFlow">
		

<!--done-->
<div id="topics">
	<div class = "post">
		<h1 class = "postTitle">
			<a id="cb_post_title_url" class="postTitle2" href="http://www.cnblogs.com/dyllove98/p/3170295.html">（转）FFMPEG解码流程</a>
		</h1>
		<div class="clear"></div>
		<div class="postBody">
			<div id="cnblogs_post_body"><p> http://www.douban.com/note/228831821/ <br /> 
 <br /> FFMPEG解码流程：
 <br /> &nbsp;
 &nbsp;
 1. 注册所有容器格式和CODEC: av_register_all()
 <br /> &nbsp;
 &nbsp;
 2. 打开文件: av_open_input_file()
 <br /> &nbsp;
 &nbsp;
 3. 从文件中提取流信息: av_find_stream_info()
 <br /> &nbsp;
 &nbsp;
 4. 穷举所有的流，查找其中种类为CODEC_TYPE_VIDEO
 <br /> &nbsp;
 &nbsp;
 5. 查找对应的解码器: avcodec_find_decoder()
 <br /> &nbsp;
 &nbsp;
 6. 打开编解码器: avcodec_open()
 <br /> &nbsp;
 &nbsp;
 7. 为解码帧分配内存: avcodec_alloc_frame()
 <br /> &nbsp;
 &nbsp;
 8. 不停地从码流中提取出帧数据: av_read_frame()
 <br /> &nbsp;
 &nbsp;
 9. 判断帧的类型，对于视频帧调用: avcodec_decode_video()
 <br /> &nbsp;
 &nbsp;
 10. 解码完后，释放解码器: avcodec_close()
 <br /> &nbsp;
 &nbsp;
 11. 关闭输入文件: avformat_close_input_file()
 <br /> 主要数据结构：
 <br /> 
 <br /> 基本概念:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 编解码器、数据帧、媒体流和容器是数字媒体处理系统的四个基本概念。
 <br /> 首先需要统一术语：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 容器／文件（Conainer/File）：即特定格式的多媒体文件。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 媒体流（Stream）：指时间轴上的一段连续数据，如一段声音数据，一段视频数据或一段字幕数据，可以是压缩的，也可以是非压缩的，压缩的数据需要关联特定的编解码器。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 数据帧／数据包（Frame/Packet）：通常，一个媒体流由大量的数据帧组成，对于压缩数据，帧对应着编解码器的最小处理单元。通常，分属于不同媒体流的数据帧交错复用于容器之中，参见交错。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 编解码器：编解码器以帧为单位实现压缩数据和原始数据之间的相互转换。
 <br /> 在FFMPEG中，使用AVFormatContext、AVStream、AVCodecContext、AVCodec及AVPacket等结构来抽象这些基本要素，它们的关系如上图所示：
 <br /> AVCodecContext：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 这是一个描述编解码器上下文的数据结构，包含了众多编解码器需要的参数信息，如下列出了部分比较重要的域：
 <br /> typedef struct AVCodecContext {
 <br /> &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *一些编解码器需要/可以像使用extradata Huffman表。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * MJPEG：Huffman表
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * RV10其他标志
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * MPEG4：全球头（也可以是在比特流或这里）
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *分配的内存应该是FF_INPUT_BUFFER_PADDING_SIZE字节较大
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *，比extradata_size避免比特流器，如果它与读prolems。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * extradata按字节的内容必须不依赖于架构或CPU的字节顺序。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 编码：设置/分配/释放由libavcodec的。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 解码：由用户设置/分配/释放。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 uint8_t *extradata;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int extradata_size;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *这是时间的基本单位，在条件（以秒为单位）
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *帧时间戳派代表出席了会议。对于固定fps的内容，
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *基应该1/framerate和时间戳的增量应该
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *相同的1。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 编码：必须由用户设置。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 解码：libavcodec的设置。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVRational time_base;
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 enum CodecID codec_id;
 <br /> &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *的fourcc（LSB在前，所以&ldquo;的ABCD&rdquo; - &gt;（&ldquo;D&rdquo;&lt;&lt; 24）（&ldquo;C&rdquo;&lt;&lt; 16）（&ldquo;B&rdquo;&lt;&lt; 8）+&ldquo;A&rdquo;）。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *这是用来解决一些编码错误。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *分路器应设置什么是编解码器用于识别领域中。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *如果有分路器等多个领域，在一个容器，然后选择一个
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *最大化使用的编解码器有关的信息。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *如果在容器中的编解码器标记字段然后32位大分路器应该
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *重新映射到一个表或其他结构的32位编号。也可选择新
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * extra_codec_tag+大小可以添加，但必须证明这是一个明显的优势
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *第一。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 编码：由用户设置，如果没有则默认基础上codec_id将使用。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 解码：由用户设置，将被转换成在初始化libavcodec的大写。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 unsigned int codec_tag;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 ......
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *在解码器的帧重排序缓冲区的大小。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *对于MPEG-2，这是IPB1或0低延时IP。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 编码：libavcodec的设置。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 解码：libavcodec的设置。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int has_b_frames;
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *每包的字节数，如果常量和已知或0
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *用于一些WAV的音频编解码器。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int block_align;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *从分路器位每个样品/像素（huffyuv需要）。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 编码：libavcodec的设置。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * - 解码：由用户设置。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int bits_per_coded_sample;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 .....
 <br /> } AVCodecContext;
 <br /> 
 <br /> 如 果是单纯使用libavcodec，这部分信息需要调用者进行初始化；如果是使用整个FFMPEG库，这部分信息在调用 avformat_open_input和avformat_find_stream_info的过程中根据文件的头信息及媒体流内的头部信息完成初始化。其中几个主要域的释义如下：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 extradata/extradata_size：这个buffer中存放了解码器可能会用到的额外信息，在av_read_frame中填充。一般来说，首先，某种具体格式的demuxer在读取格式头信息的时候会填充extradata，其次，如果 demuxer没有做这个事情，比如可能在头部压根儿就没有相关的编解码信息，则相应的parser会继续从已经解复用出来的媒体流中继续寻找。在没有找到任何额外信息的情况下，这个buffer指针为空。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 time_base：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 width/height：视频的宽和高。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 sample_rate/channels：音频的采样率和信道数目。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 sample_fmt：音频的原始采样格式。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 codec_name/codec_type/codec_id/codec_tag：编解码器的信息。
 <br /> AVStrea
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 该结构体描述一个媒体流，定义如下：
 <br /> typedef struct AVStream {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int index;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVCodecContext *codec;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *流的实时帧率基地。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *这是所有时间戳可以最低帧率
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *准确代表（它是所有的最小公倍数
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *流的帧率）。请注意，这个值只是一个猜测！
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *例如，如果时间基数为1/90000和所有帧
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *约3600或1800计时器刻度，，然后r_frame_rate将是50/1。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVRational r_frame_rate;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *这是时间的基本单位，在条件（以秒为单位）
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *帧时间戳派代表出席了会议。对于固定fps的内容，
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *时基应该是1/framerate的时间戳的增量应为1。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVRational time_base;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 ......
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *解码流量的第一帧，在流量时-base分。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *如果你是绝对100％的把握，设定值
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *它真的是第一帧点。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *这可能是未定义（AV_NOPTS_VALUE）的。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *@注意的业余头不弱者受制与正确的START_TIME的业余
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *分路器必须不设定此。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int64_t start_time;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / **
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *解码：时间流流时基。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *如果源文件中没有指定的时间，但不指定
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 *比特率，这个值将被从码率和文件大小的估计。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 * /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int64_t duration;
 <br /> #if LIBAVFORMAT_VERSION_INT &lt; (53&lt;&lt;16)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char language[4];
 <br /> #endif
 <br /> &nbsp;
 &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / *流信息* /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int64_t timestamp;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #if LIBAVFORMAT_VERSION_INT &lt; (53&lt;&lt;16)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char title[512];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char author[512];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char copyright[512];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char comment[512];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char album[512];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int year;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int track;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char genre[32];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #endif
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int ctx_flags;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int64_t data_offset;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int index_built;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int mux_rate;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 unsigned int packet_size;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int preload;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int max_delay;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_NOOUTPUTLOOP -1
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_INFINITEOUTPUTLOOP 0
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int loop_output;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int flags;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_FLAG_GENPTS 0x0001 ///&lt; 生成失踪分，即使它需要解析未来框架。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_FLAG_IGNIDX 0x0002 ///&lt; 忽略指数。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_FLAG_NONBLOCK 0x0004 ///&lt;从输入中读取数据包时，不要阻止。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_FLAG_IGNDTS 0x0008 ///&lt; 忽略帧的DTS包含DTS与PTS
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_FLAG_NOFILLIN 0x0010 ///&lt; 不要从任何其他值推断值，只是返回存储在容器中
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_FLAG_NOPARSE 0x0020 ///&lt; 不要使用AVParsers，你还必须设置为FILLIN帧代码的工作，没有解析AVFMT_FLAG_NOFILLIN - &gt;无帧。也在寻求框架不能工作，如果找到帧边界的解析已被禁用
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define AVFMT_FLAG_RTP_HINT 0x0040 ///&lt; 暗示到输出文件添加的RTP
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int loop_input;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 CODEC_ID_MPEG1VIDEO,
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 CODEC_ID_MPEG2VIDEO, ///&lt; preferred ID for MPEG-1/2 video decoding
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 CODEC_ID_MPEG2VIDEO_XVMC,
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 CODEC_ID_H261,
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 CODEC_ID_H263,
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 ...
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 };
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 通常，如果某种媒体格式具备完备而正确的头信息，调用avformat_open_input即可以得到这两个参数，但若是因某种原因 avformat_open_input无法获取它们，这一任务将由avformat_find_stream_info完成。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 其次还要获取各媒体流对应编解码器的时间基准。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 此外，对于音频编解码器，还需要得到：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 采样率，
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 声道数，
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 位宽，
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 帧长度（对于某些编解码器是必要的），
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 对于视频编解码器，则是：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 图像大小，
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 色彩空间及格式，
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 av_read_frame
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int av_read_frame(AVFormatContext *s, AVPacket *pkt);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 这个函数用于从多媒体文件或多媒体流中读取媒体数据，获取的数据由AVPacket结构pkt来存放。对于音频数据，如果是固定比特率，则pkt中装载着一个或多个音频帧；如果是可变比特率，则pkt中装载有一个音频帧。对于视频数据，pkt中装载有一个视频帧。需要注意的是：再次调用本函数之前，必须使用 av_free_packet释放pkt所占用的资源。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 通过pkt&rarr;stream_index可以查到获取的媒体数据的类型，从而将数据送交相应的解码器进行后续处理。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 av_seek_frame
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int av_seek_frame(AVFormatContext *s, int stream_index, int64_t timestamp, int flags);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 这个函数通过改变媒体文件的读写指针来实现对媒体文件的随机访问，支持以下三种方式：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 基于时间的随机访问：具体而言就是将媒体文件读写指针定位到某个给定的时间点上，则之后调用av_read_frame时能够读到时间标签等于给定时间点的媒体数据，通常用于实现媒体播放器的快进、快退等功能。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 基于文件偏移的随机访问：相当于普通文件的seek函数，timestamp也成为文件的偏移量。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 基于帧号的随机访问：timestamp为要访问的媒体数据的帧号。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 关于参数：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 s：是个AVFormatContext指针，就是avformat_open_input返回的那个结构。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 stream_index：指定媒体流，如果是基于时间的随机访问，则第三个参数timestamp将以此媒体流的时间基准为单位；如果设为负数，则相当于不指定具体的媒体流，FFMPEG会按照特定的算法寻找缺省的媒体流，此时，timestamp的单位为AV_TIME_BASE（微秒）。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 timestamp：时间标签，单位取决于其他参数。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 flags：定位方式，AVSEEK_FLAG_BYTE表示基于字节偏移，AVSEEK_FLAG_FRAME表示基于帧号，其它表示基于时间。
 <br /> av_close_input_file:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 void av_close_input_file(AVFormatContext *s);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 关闭一个媒体文件：释放资源，关闭物理IO。
 <br /> avcodec_find_decoder:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVCodec *avcodec_find_decoder(enum CodecID id);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVCodec *avcodec_find_decoder_by_name(const char *name);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 根据给定的codec id或解码器名称从系统中搜寻并返回一个AVCodec结构的指针。
 <br /> avcodec_open:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int avcodec_open(AVCodecContext *avctx, AVCodec *codec);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 此函数根据输入的AVCodec指针具体化AVCodecContext结构。在调用该函数之前，需要首先调用avcodec_alloc_context 分配一个AVCodecContext结构，或调用avformat_open_input获取媒体文件中对应媒体流的AVCodecContext结构；此外还需要通过avcodec_find_decoder获取AVCodec结构。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 这一函数还将初始化对应的解码器。
 <br /> avcodec_decode_video2
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture, int *got_picture_ptr, AVPacket *avpkt);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 解码一个视频帧。got_picture_ptr指示是否有解码数据输出。
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 输入数据在AVPacket结构中，输出数据在AVFrame结构中。AVFrame是定义在avcodec.h中的一个数据结构：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 typedef struct AVFrame {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 FF_COMMON_FRAME
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 } AVFrame;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 FF_COMMON_FRAME定义了诸多数据域，大部分由FFMpeg内部使用，对于用户来说，比较重要的主要包括：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 #define FF_COMMON_FRAME \
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 ......
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 uint8_t *data[4];\
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int linesize[4];\
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int key_frame;\
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int pict_type;\
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int64_t pts;\
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int reference;\
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 ......
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 FFMpeg内部以planar的方式存储原始图像数据，即将图像像素分为多个平面（R/G/B或Y/U/V），data数组内的指针分别指向四个像素平面的起始位置，linesize数组则存放各个存贮各个平面的缓冲区的行宽：
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 +++data[0]-&gt;#################################++++++++++++
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 ++++++++++++###########picture data##########++++++++++++
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 ........................
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 ++++++++++++#################################++++++++++++
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 |&lt;-------------------line_size[0]----------------------&gt;|
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 此外，key_frame标识该图像是否是关键帧；pict_type表示该图像的编码类型：I(1)/P(2)/B(3)&hellip;&hellip;；pts是以 time_base为单位的时间标签，对于部分解码器如H.261、H.263和MPEG4，可以从头信息中获取；reference表示该图像是否被用作参考。
 <br /> avcodec_decode_audio4
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int avcodec_decode_audio4(AVCodecContext *avctx, AVFrame *frame, int *got_frame_ptr, AVPacket *avpkt);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 解码一个音频帧。输入数据在AVPacket结构中，输出数据在frame中，got_frame_ptr表示是否有数据输出。
 <br /> avcodec_close
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int avcodec_close(AVCodecContext *avctx);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 关闭解码器，释放avcodec_open中分配的资源。
 <br /> 测试程序
 <br /> #include
 <br /> #include
 <br /> #include
 <br /> #include
 <br /> #include "libavutil/avstring.h"
 <br /> #include "libavformat/avformat.h"
 <br /> #include "libavdevice/avdevice.h"
 <br /> #include "libavcodec/opt.h"
 <br /> #include "libswscale/swscale.h"
 <br /> #define DECODED_AUDIO_BUFFER_SIZE 192000
 <br /> struct options
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int streamId;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int frames;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int nodec;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int bplay;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int thread_count;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int64_t lstart;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char finput[256];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char foutput1[256];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char foutput2[256];
 <br /> };
 <br /> int parse_options(struct options *opts, int argc, char** argv)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int optidx;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 char *optstr;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (argc &lt; 2) return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;streamId = -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;lstart = -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;frames = -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;foutput1[0] = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;foutput2[0] = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;nodec = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;bplay = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;thread_count = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 strcpy(opts-&gt;finput, argv[1]);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 optidx = 2;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 while (optidx &lt; argc)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 optstr = argv[optidx++];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (*optstr++ != '-') return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 switch (*optstr++)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case 's': //&lt; stream id
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;streamId = atoi(optstr);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 break;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case 'f': //&lt; frames
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;frames = atoi(optstr);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 break;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case 'k': //&lt; skipped
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;lstart = atoll(optstr);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 break;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case 'o': //&lt; output
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 strcpy(opts-&gt;foutput1, optstr);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 strcat(opts-&gt;foutput1, ".mpg");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 strcpy(opts-&gt;foutput2, optstr);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 strcat(opts-&gt;foutput2, ".raw");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 break;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case 'n': //decoding and output options
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (strcmp("dec", optstr) == 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;nodec = 1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 break;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case 'p':
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;bplay = 1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 break;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case 't':
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 opts-&gt;thread_count = atoi(optstr);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 break;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 default:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return 0;
 <br /> }
 <br /> void show_help(char* program)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("简单的FFMPEG测试方案\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("Usage: %s inputfile [-sstreamid [-fframes] [-kskipped] [-ooutput_filename(without extension)] [-p] [-tthread_count］\n",
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 program);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return;
 <br /> }
 <br /> static void log_callback(void* ptr, int level, const char* fmt, va_list vl)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 vfprintf(stdout, fmt, vl);
 <br /> }
 <br /> / *音频渲染器的代码（OSS）*/
 <br /> #include
 <br /> #include
 <br /> #include
 <br /> #include
 <br /> #define OSS_DEVICE "/dev/dsp0"
 <br /> struct audio_dsp
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int audio_fd;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int channels;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int format;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int speed;
 <br /> };
 <br /> int map_formats(enum SampleFormat format)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 switch(format)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case SAMPLE_FMT_U8:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return AFMT_U8;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 case SAMPLE_FMT_S16:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return AFMT_S16_LE;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 default:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return AFMT_U8;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> }
 <br /> int set_audio(struct audio_dsp* dsp)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (dsp-&gt;audio_fd == -1)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("无效的音频DSP ID!\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (-1 == ioctl(dsp-&gt;audio_fd, SNDCTL_DSP_SETFMT, &amp;dsp-&gt;format))
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("无法设置DSP格式!\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (-1 == ioctl(dsp-&gt;audio_fd, SNDCTL_DSP_CHANNELS, &amp;dsp-&gt;channels))
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("无法设置DSP格式!\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (-1 == ioctl(dsp-&gt;audio_fd, SNDCTL_DSP_SPEED, &amp;dsp-&gt;speed))
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("无法设置DSP格式!\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return 0;
 <br /> }
 <br /> int play_pcm(struct audio_dsp* dsp, unsigned char *buf, int size)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (dsp-&gt;audio_fd == -1)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("无效的音频DSP ID！\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (-1 == write(dsp-&gt;audio_fd, buf, size))
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("音频DSP无法写入！\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return 0;
 <br /> }
 <br /> 
 <br /> 
 <br /> #include
 <br /> #include
 <br /> &nbsp;
 
 <br /> #define FB_DEVICE "/dev/fb0"
 <br /> &nbsp;
 
 <br /> enum pic_format
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 eYUV_420_Planer,
 <br /> };
 <br /> struct video_fb
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int video_fd;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 struct fb_var_screeninfo vinfo;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 struct fb_fix_screeninfo finfo;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 unsigned char *fbp;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVFrame *frameRGB;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 struct
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int x;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int y;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 } video_pos;
 <br /> };
 <br /> int open_video(struct video_fb *fb, int x, int y)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int screensize;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fb-&gt;video_fd = open(FB_DEVICE, O_WRONLY);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (fb-&gt;video_fd == -1) return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (ioctl(fb-&gt;video_fd, FBIOGET_FSCREENINFO, &amp;fb-&gt;finfo)) return -2;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (ioctl(fb-&gt;video_fd, FBIOGET_VSCREENINFO, &amp;fb-&gt;vinfo)) return -2;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("视频设备：分解 %dx%d, �pp\n", fb-&gt;vinfo.xres, fb-&gt;vinfo.yres, fb-&gt;vinfo.bits_per_pixel);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 screensize = fb-&gt;vinfo.xres * fb-&gt;vinfo.yres * fb-&gt;vinfo.bits_per_pixel / 8;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fb-&gt;fbp = (unsigned char *) mmap(0, screensize, PROT_READ|PROT_WRITE, MAP_SHARED, fb-&gt;video_fd, 0);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (fb-&gt;fbp == -1) return -3;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (x &gt;= fb-&gt;vinfo.xres || y &gt;= fb-&gt;vinfo.yres)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -4;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 else
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fb-&gt;video_pos.x = x;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fb-&gt;video_pos.y = y;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fb-&gt;frameRGB = avcodec_alloc_frame();
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (!fb-&gt;frameRGB) return -5;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return 0;
 <br /> }
 <br /> #if 0
 <br /> 
 <br /> int show_picture(struct video_fb *fb, AVFrame *frame, int width, int height, enum pic_format format)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 struct SwsContext *sws;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int i;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 unsigned char *dest;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 unsigned char *src;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (fb-&gt;video_fd == -1) return -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if ((fb-&gt;video_pos.x &gt;= fb-&gt;vinfo.xres) || (fb-&gt;video_pos.y &gt;= fb-&gt;vinfo.yres)) return -2;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (fb-&gt;video_pos.x + width &gt; fb-&gt;vinfo.xres)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 width = fb-&gt;vinfo.xres - fb-&gt;video_pos.x;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (fb-&gt;video_pos.y + height &gt; fb-&gt;vinfo.yres)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 height = fb-&gt;vinfo.yres - fb-&gt;video_pos.y;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (format == PIX_FMT_YUV420P)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 sws = sws_getContext(width, height, format, width, height, PIX_FMT_RGB32, SWS_FAST_BILINEAR, NULL, NULL, NULL);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (sws == 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -3;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (sws_scale(sws, frame-&gt;data, frame-&gt;linesize, 0, height, fb-&gt;frameRGB-&gt;data, fb-&gt;frameRGB-&gt;linesize))
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return -3;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dest = fb-&gt;fbp + (fb-&gt;video_pos.x+fb-&gt;vinfo.xoffset) * (fb-&gt;vinfo.bits_per_pixel/8) +(fb-&gt;video_pos.y+fb-&gt;vinfo.yoffset) * fb-&gt;finfo.line_length;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 for (i = 0; i &lt; height; i++)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 memcpy(dest, src, width*4);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 src += fb-&gt;frameRGB-&gt;linesize[0];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dest += fb-&gt;finfo.line_length;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return 0;
 <br /> }
 <br /> #endif
 <br /> void close_video(struct video_fb *fb)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (fb-&gt;video_fd != -1)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 munmap(fb-&gt;fbp, fb-&gt;vinfo.xres * fb-&gt;vinfo.yres * fb-&gt;vinfo.bits_per_pixel / 8);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 close(fb-&gt;video_fd);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fb-&gt;video_fd = -1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> }
 <br /> 
 <br /> &nbsp;
 
 <br /> int main(int argc, char **argv)
 <br /> {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVFormatContext* pCtx = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVCodecContext *pCodecCtx = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVCodec *pCodec = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVPacket packet;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 AVFrame *pFrame = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 FILE *fpo1 = NULL;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 FILE *fpo2 = NULL;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int nframe;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int err;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int got_picture;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int picwidth, picheight, linesize;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 unsigned char *pBuf;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int i;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int64_t timestamp;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 struct options opt;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int usefo = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 struct audio_dsp dsp;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int dusecs;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 float usecs1 = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 float usecs2 = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 struct timeval elapsed1, elapsed2;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int decoded = 0;
 <br /> 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 av_register_all();
 <br /> 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 av_log_set_callback(log_callback);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 av_log_set_level(50);
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (parse_options(&amp;opt, argc, argv) &lt; 0 || (strlen(opt.finput) == 0))
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 show_help(argv[0]);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 err = avformat_open_input(&amp;pCtx, opt.finput, 0, 0);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (err &lt; 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt;(avformat_open_input)\tERROR:\t%d\n", err);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 err = avformat_find_stream_info(pCtx, 0);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (err &lt; 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt;(avformat_find_stream_info)\tERROR:\t%d\n", err);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (opt.streamId &lt; 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 av_dump_format(pCtx, 0, pCtx-&gt;filename, 0);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 else
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n 额外的数据流 %d (�):", opt.streamId, pCtx-&gt;streams[opt.streamId]-&gt;codec-&gt;extradata_size);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 for (i = 0; i &lt; pCtx-&gt;streams[opt.streamId]-&gt;codec-&gt;extradata_size; i++)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (i == 0) printf("\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("%2x ", pCtx-&gt;streams[opt.streamId]-&gt;codec-&gt;extradata[i]);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / *尝试打开输出文件*/
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (strlen(opt.foutput1) &amp;&amp; strlen(opt.foutput2))
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fpo1 = fopen(opt.foutput1, "wb");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fpo2 = fopen(opt.foutput2, "wb");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (!fpo1 || !fpo2)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt;error 打开输出文件\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 usefo = 1;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 else
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 usefo = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (opt.streamId &gt;= pCtx-&gt;nb_streams)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt;StreamId\tERROR\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (opt.lstart &gt; 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 err = av_seek_frame(pCtx, opt.streamId, opt.lstart, AVSEEK_FLAG_ANY);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (err &lt; 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt;(av_seek_frame)\tERROR:\t%d\n", err);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 / *解码器的配置*/
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (!opt.nodec)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pCodecCtx = pCtx-&gt;streams[opt.streamId]-&gt;codec;
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (opt.thread_count &lt;= 16 &amp;&amp; opt.thread_count &gt; 0 )
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pCodecCtx-&gt;thread_count = opt.thread_count;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pCodecCtx-&gt;thread_type = FF_THREAD_FRAME;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pCodec = avcodec_find_decoder(pCodecCtx-&gt;codec_id);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (!pCodec)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt;不能找到编解码器!\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 err = avcodec_open2(pCodecCtx, pCodec, 0);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (err &lt; 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt;(avcodec_open)\tERROR:\t%d\n", err);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pFrame = avcodec_alloc_frame();
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / *准备设备* /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (opt.bplay)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / *音频设备* /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dsp.audio_fd = open(OSS_DEVICE, O_WRONLY);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (dsp.audio_fd == -1)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt; 无法打开音频设备\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dsp.channels = pCodecCtx-&gt;channels;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dsp.speed = pCodecCtx-&gt;sample_rate;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dsp.format = map_formats(pCodecCtx-&gt;sample_fmt);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (set_audio(&amp;dsp) &lt; 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt; 不能设置音频设备\n");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 goto fail;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 / *视频设备* /
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 nframe = 0;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 while(nframe &lt; opt.frames || opt.frames == -1)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 gettimeofday(&amp;elapsed1, NULL);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 err = av_read_frame(pCtx, &amp;packet);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (err &lt; 0)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n-&gt;(av_read_frame)\tERROR:\t%d\n", err);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 break;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 gettimeofday(&amp;elapsed2, NULL);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dusecs = (elapsed2.tv_sec - elapsed1.tv_sec)*1000000 + (elapsed2.tv_usec - elapsed1.tv_usec);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 usecs2 += dusecs;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 timestamp = av_rescale_q(packet.dts, pCtx-&gt;streams[packet.stream_index]-&gt;time_base, (AVRational){1, AV_TIME_BASE});
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\nFrame No ] stream#%d\tsize mB, timestamp:%6lld, dts:%6lld, pts:%6lld, ", nframe++, packet.stream_index, packet.size,
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 timestamp, packet.dts, packet.pts);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (packet.stream_index == opt.streamId)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> #if 0
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 for (i = 0; i &lt; 16; i++)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (i == 0) printf("\n pktdata: ");
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("%2x ", packet.data[i]);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n");
 <br /> #endif
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (usefo)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fwrite(packet.data, packet.size, 1, fpo1);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fflush(fpo1);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (pCtx-&gt;streams[opt.streamId]-&gt;codec-&gt;codec_type == AVMEDIA_TYPE_VIDEO &amp;&amp; !opt.nodec)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 picheight = pCtx-&gt;streams[opt.streamId]-&gt;codec-&gt;height;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 picwidth = pCtx-&gt;streams[opt.streamId]-&gt;codec-&gt;width;
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 gettimeofday(&amp;elapsed1, NULL);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 avcodec_decode_video2(pCodecCtx, pFrame, &amp;got_picture, &amp;packet);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 decoded++;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 gettimeofday(&amp;elapsed2, NULL);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dusecs = (elapsed2.tv_sec - elapsed1.tv_sec)*1000000 + (elapsed2.tv_usec - elapsed1.tv_usec);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 usecs1 += dusecs;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (got_picture)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("[Video: type %d, ref %d, pts %lld, pkt_pts %lld, pkt_dts %lld]",
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pFrame-&gt;pict_type, pFrame-&gt;reference, pFrame-&gt;pts, pFrame-&gt;pkt_pts, pFrame-&gt;pkt_dts);
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (pCtx-&gt;streams[opt.streamId]-&gt;codec-&gt;pix_fmt == PIX_FMT_YUV420P)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (usefo)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 linesize = pFrame-&gt;linesize[0];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pBuf = pFrame-&gt;data[0];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 for (i = 0; i &lt; picheight; i++)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fwrite(pBuf, picwidth, 1, fpo2);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pBuf += linesize;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 linesize = pFrame-&gt;linesize[1];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pBuf = pFrame-&gt;data[1];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 for (i = 0; i &lt; picheight/2; i++)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fwrite(pBuf, picwidth/2, 1, fpo2);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pBuf += linesize;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 linesize = pFrame-&gt;linesize[2];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pBuf = pFrame-&gt;data[2];
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 for (i = 0; i &lt; picheight/2; i++)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fwrite(pBuf, picwidth/2, 1, fpo2);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 pBuf += linesize;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fflush(fpo2);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (opt.bplay)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 av_free_packet(&amp;packet);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 else if (pCtx-&gt;streams[opt.streamId]-&gt;codec-&gt;codec_type == AVMEDIA_TYPE_AUDIO &amp;&amp; !opt.nodec)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 int got;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 gettimeofday(&amp;elapsed1, NULL);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 avcodec_decode_audio4(pCodecCtx, pFrame, &amp;got, &amp;packet);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 decoded++;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 gettimeofday(&amp;elapsed2, NULL);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 dusecs = (elapsed2.tv_sec - elapsed1.tv_sec)*1000000 + (elapsed2.tv_usec - elapsed1.tv_usec);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 usecs1 += dusecs;
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (got)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("[Audio: ]B raw data, decoding time: %d]", pFrame-&gt;linesize[0], dusecs);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (usefo)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fwrite(pFrame-&gt;data[0], pFrame-&gt;linesize[0], 1, fpo2);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fflush(fpo2);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (opt.bplay)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 play_pcm(&amp;dsp, pFrame-&gt;data[0], pFrame-&gt;linesize[0]);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (!opt.nodec &amp;&amp; pCodecCtx)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 avcodec_close(pCodecCtx);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("\n%d 帧解析, average %.2f us per frame\n", nframe, usecs2/nframe);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 printf("%d 帧解码，平均 %.2f 我们每帧\n", decoded, usecs1/decoded);
 <br /> &nbsp;
 
 <br /> fail:
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (pCtx)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 avformat_close_input(&amp;pCtx);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (fpo1)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fclose(fpo1);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (fpo2)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 fclose(fpo2);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (!pFrame)
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 av_free(pFrame);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 if (!usefo &amp;&amp; (dsp.audio_fd != -1))
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 {
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 close(dsp.audio_fd);
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 }
 <br /> &nbsp;
 &nbsp;
 &nbsp;
 &nbsp;
 return 0;}
 <br /> 
 <br /> 
 <br /> 
 <br /> 
 <br /> 
 <br /> 
 <br /> 
 </p>
<p style="text-indent: 2em;">本文以H264视频流为例，讲解解码流数据的步骤。</p>
<p style="text-indent: 2em;">为突出重点，本文只专注于讨论解码视频流数据，不涉及其它（如开发环境的配置等）。如果您需要这方面的信息，请和我联系。</p>
<p> 
 <br /> 准备变量
 </p>
<p style="text-indent: 2em;">定义AVCodecContext。如果您使用类，可以定义成类成员。我这里定义成全局变量。</p>
<p style="text-indent: 2em;">static AVCodecContext * g_pCodecCtx = NULL;</p>
<p style="text-indent: 2em;">定义一个AVFrame，AVFrame描述一个多媒体帧。解码后的数据将被放在其中。</p>
<p style="text-indent: 2em;">static AVFrame * g_pavfFrame = NULL;</p>
<p> 
 <br /> 初始化解码器
 </p>
<p style="text-indent: 2em;">现在开始初始化您的解码器。我把整个初始化过程包在了一个函数里，除非您有更好的主意，我建议您也这么做。函数长得象这样：</p>
<p style="text-indent: 2em;">BOOL H264_Init()</p>
<p style="text-indent: 2em;">{</p>
<p>&nbsp;</p>
<p style="text-indent: 2em;">&hellip;</p>
<p>&nbsp;</p>
<p style="text-indent: 2em;">}</p>
<p style="text-indent: 2em;">初始化libavcodec，MMPEG要求，这个函数一定要第一个被调用：</p>
<p style="text-indent: 2em;">avcodec_init();</p>
<p style="text-indent: 2em;">挂上所有的codec。也许只挂一个H264的codec就行，我没试过：</p>
<p style="text-indent: 2em;">av_register_all();</p>
<p style="text-indent: 2em;">得到H264的解码器：</p>
<p style="text-indent: 2em;">AVCodec * pCodec = avcodec_find_decoder(CODEC_ID_H264);</p>
<p style="text-indent: 2em;">创建一个AVCodecContext，并用默认值初始化：</p>
<p style="text-indent: 2em;">g_pCodecCtx = avcodec_alloc_context();</p>
<p style="text-indent: 2em;">更改g_pCodecCtx的一些成员变量的值，您应该从解码方得到这些变量值：</p>
<p style="text-indent: 2em;">g_pCodecCtx-&gt;time_base.num = 1; //这两行：一秒钟25帧</p>
<p style="text-indent: 2em;">g_pCodecCtx-&gt;time_base.den = 25;</p>
<p style="text-indent: 2em;">g_pCodecCtx-&gt;bit_rate = 0; //初始化为0</p>
<p style="text-indent: 2em;">g_pCodecCtx-&gt;frame_number = 1; //每包一个视频帧</p>
<p style="text-indent: 2em;">g_pCodecCtx-&gt;codec_type = CODEC_TYPE_VIDEO;</p>
<p style="text-indent: 2em;">g_pCodecCtx-&gt;width = 704; //这两行：视频的宽度和高度</p>
<p style="text-indent: 2em;">g_pCodecCtx-&gt;height = 576;</p>
<p style="text-indent: 2em;">打开codec。如果打开成功的话，分配AVFrame：</p>
<p style="text-indent: 2em;">if(avcodec_open(g_pCodecCtx, pCodec) &gt;= 0)</p>
<p style="text-indent: 2em;">{</p>
<p style="text-indent: 2em;">g_pavfFrame = avcodec_alloc_frame();// Allocate video frame</p>
<p style="text-indent: 2em;">}</p>
<p style="text-indent: 2em;">列出完整的初始化解码库的代码：</p>
<p style="text-indent: 2em;"><a href="https://nvhxyw.bay.livefilestore.com/y1mc79fV-ol4SAyfYXZ3WPYXHeRC8_3qNKufFW_iDSdgLuPFiXtH8s7Z0F0t6VjoF_wf-jj0MDVabRNfnir2TF3XXj9HrXRl8wTPJp-SVeQA0nY8sEusC0qdE2YWToLhG4aSkCktepcFqOsYf9Ib8glwA/image[12].png"><img title="（转）FFMPEG解码流程" alt="image" width="671" height="1019" border="0" /></a></p>
<p> 
 <br /> 解码
 </p>
<p style="text-indent: 2em;">如果您只要求解成YUV 420I数据，只需一次调用就可以了：</p>
<p style="text-indent: 2em;">avcodec_decode_video(g_pCodecCtx, g_pavfFrame, (int *)&amp;nGot, (unsigned __int8 *)pSrcData, dwDataLen);</p>
<p style="text-indent: 2em;">这里，nGot用来返回解码成功与否，avcodec_decode_video调用完成后，如果nGot不等于0,则表示解码成功，否则未解出视频帧。</p>
<p style="text-indent: 2em;">pSrcData是待解的H264编码的一段数据流，dwDataLen表示该段数据流的长度，单位是byte。</p>
<p style="text-indent: 2em;">解码后的视频帧（YUV数据）被存入g_pavfFrame，g_pavfFrame-&gt;data[0]、 g_pavfFrame-&gt;data[1]、g_pavfFrame-&gt;data[2]即是YUV数据。下面的示例代码把YUV数据压在了一块内存里，排列方式为：</p>
<p style="text-indent: 2em;">YY</p>
<p style="text-indent: 2em;">YY</p>
<p style="text-indent: 2em;">U</p>
<p style="text-indent: 2em;">V</p>
<p style="text-indent: 2em;">该函数有返回值：如果解码成功，则返回本次解码使用的码流字节数，否则返回0。为简单起见，我这里假设pSrcData只包含一个视频帧。</p>
<p style="text-indent: 2em;">同样，出于模块化的要求和代码维护的方便，我把解码动作也包在了一个函数里:</p>
<p style="text-indent: 2em;">BOOL H264_Decode(const PBYTE pSrcData, const DWORD dwDataLen, PBYTE pDeData, int * pnWidth, int * pnHeight)</p>
<p style="text-indent: 2em;">pSrcData &ndash; 待解码数据</p>
<p style="text-indent: 2em;">dwDataLen &ndash; 待解码数据字节数</p>
<p style="text-indent: 2em;">pDeData &ndash; 用来返回解码后的YUV数据</p>
<p style="text-indent: 2em;">pnWidth， pnHeight &ndash; 用来返回视频的长度和宽度</p>
<p style="text-indent: 2em;">下面列出完整的代码：</p>
<p style="text-indent: 2em;"><a href="https://nvhxyw.bay.livefilestore.com/y1mQpgodxbdGh_i2be-Vh3u9Ub-YQw72bkXdVnKwqTMWjrIUdlxGiy5C1TBmThkWtMKE6BmAvkN6rgTCYcm_5A5dBk__WCYgXZJlPPWS8RRNgYj8nl2KQRnuxeLqUrVSzdRYKgr7PZYeRAOh8mwjK80aw/image[11].png"><img title="（转）FFMPEG解码流程" alt="image" width="706" height="866" border="0" /></a></p>
<p> 
 <br /> 释放解码器
 </p>
<p style="text-indent: 2em;">以上其实已经完成了本文的任务，但从负责任的角度，要善始善终嘛。</p>
<p style="text-indent: 2em;">释放的过程没什么好说的，一看就明白。同样，我也把它们包在了一个函数里：</p>
<p style="text-indent: 2em;"><a href="https://nvhxyw.bay.livefilestore.com/y1mB365VAzj-GXdvTM8D9hQZk4ge2R8-Z_v8Zy5cleAHwymXIKaH-XYIrdgr74viXfIFKdcoUgDPWG-ff0b0Kc8trQozy4Zdjpdwty1TnRpPUUHA8Sy2PAGVJvvPLvwHMqk5ckMQPtCpAIoktRB9qVQYA/image[16].png"><img title="（转）FFMPEG解码流程" alt="image" width="706" height="510" border="0" /></a></p>
<p style="text-indent: 2em;">（抱歉的很，文章本来是用Word写的，代码块是一个个文本框，但贴到这里却变成了图片。）</p>
<div>
  
  <br /> &nbsp;
  下面是如果解码以及将 YV12 数据转换成
  <br /> 32 位 ARGB 数据的代码
  <br /> 1
  <br /> 2 #include "avcodec.h"
  <br /> 3 #include "h264decoder.h";
  <br /> 4
  <br /> 5 typedef unsigned char byte_t;
  <br /> 6 typedef unsigned int uint_t;
  <br /> 7
  <br /> 8 struct AVCodec *fCodec = NULL; // Codec
  <br /> 9 struct AVCodecContext *fCodecContext = NULL; // Codec Context
  <br /> 10 struct AVFrame *fVideoFrame = NULL; // Frame
  <br /> 11
  <br /> 12 int fDisplayWidth = 0;
  <br /> 13 int fDisplayHeight = 0;
  <br /> 14 int *fColorTable = NULL;
  <br /> 15
  <br /> 16 int avcodec_decode_video(AVCodecContext *avctx, AVFrame *picture,
  <br /> 17 int *got_picture_ptr,
  <br /> 18 const uint8_t *buf, int buf_size)
  <br /> 19 {
  <br /> 20 AVPacket avpkt;
  <br /> 21 av_init_packet(&amp;avpkt);
  <br /> 22 avpkt.data = buf;
  <br /> 23 avpkt.size = buf_size;
  <br /> 24 // HACK for CorePNG to decode as normal PNG by default
  <br /> 25 avpkt.flags = AV_PKT_FLAG_KEY;
  <br /> 26 return avcodec_decode_video2(avctx, picture, got_picture_ptr, &amp;avpkt);
  <br /> 27 }
  <br /> 28
  <br /> 29 #define RGB_V(v) ((v &lt; 0) ? 0 : ((v &gt; 255) ? 255 : v))
  <br /> 30
  <br /> 31 void DeleteYUVTable()
  <br /> 32 {
  <br /> 33 av_free(fColorTable);
  <br /> 34 }
  <br /> 35
  <br /> 36 void CreateYUVTable()
  <br /> 37 {
  <br /> 38 int i;
  <br /> 39 int u, v;
  <br /> 40 int *u_b_tab = NULL;
  <br /> 41 int *u_g_tab = NULL;
  <br /> 42 int *v_g_tab = NULL;
  <br /> 43 int *v_r_tab = NULL;
  <br /> 44
  <br /> 45 fColorTable = (int *)av_malloc(4 * 256 * sizeof(int));
  <br /> 46 u_b_tab = &amp;fColorTable[0 * 256];
  <br /> 47 u_g_tab = &amp;fColorTable[1 * 256];
  <br /> 48 v_g_tab = &amp;fColorTable[2 * 256];
  <br /> 49 v_r_tab = &amp;fColorTable[3 * 256];
  <br /> 50
  <br /> 51 for (i = 0; i &lt; 256; i++) {
  <br /> 52 u = v = (i - 128);
  <br /> 53 u_b_tab[i] = (int) ( 1.772 * u);
  <br /> 54 u_g_tab[i] = (int) ( 0.34414 * u);
  <br /> 55 v_g_tab[i] = (int) ( 0.71414 * v);
  <br /> 56 v_r_tab[i] = (int) ( 1.402 * v);
  <br /> 57 }
  <br /> 58 }
  <br /> 59
  <br /> 60
  <br /> 61 void DisplayYUV_32(uint_t *displayBuffer, int videoWidth, int videoHeight, int outPitch)
  <br /> 62 {
  <br /> 63 int *u_b_tab = &amp;fColorTable[0 * 256];
  <br /> 64 int *u_g_tab = &amp;fColorTable[1 * 256];
  <br /> 65 int *v_g_tab = &amp;fColorTable[2 * 256];
  <br /> 66 int *v_r_tab = &amp;fColorTable[3 * 256];
  <br /> 67
  <br /> 68 // YV12: [Y:MxN] [U:M/2xN/2] [V:M/2xN/2]
  <br /> 69 byte_t* y = fVideoFrame-&gt;data[0];
  <br /> 70 byte_t* u = fVideoFrame-&gt;data[1];
  <br /> 71 byte_t* v = fVideoFrame-&gt;data[2];
  <br /> 72
  <br /> 73 int src_ystride = fVideoFrame-&gt;linesize[0];
  <br /> 74 int src_uvstride = fVideoFrame-&gt;linesize[1];
  <br /> 75
  <br /> 76 int i, line;
  <br /> 77 int r, g, b;
  <br /> 78
  <br /> 79 int ub, ug, vg, vr;
  <br /> 80
  <br /> 81 int width = videoWidth;
  <br /> 82 int height = videoHeight;
  <br /> 83
  <br /> 84 // 剪切边框
  <br /> 85 if (width &gt; fDisplayWidth) {
  <br /> 86 width = fDisplayWidth;
  <br /> 87 y += (videoWidth - fDisplayWidth) / 2;
  <br /> 88 u += (videoWidth - fDisplayWidth) / 4;
  <br /> 89 v += (videoWidth - fDisplayWidth) / 4;
  <br /> 90 }
  <br /> 91
  <br /> 92 if (height &gt; fDisplayHeight) {
  <br /> 93 height = fDisplayHeight;
  <br /> 94 }
  <br /> 95
  <br /> 96 for (line = 0; line &lt; height; line++) {
  <br /> 97 byte_t* yoff = y + line * src_ystride;
  <br /> 98 byte_t* uoff = u + (line / 2) * src_uvstride;
  <br /> 99 byte_t* voff = v + (line / 2) * src_uvstride;
  <br /> 100 //uint_t* buffer = displayBuffer + (height - line - 1) * outPitch;
  <br /> 101 uint_t* buffer = displayBuffer + line * outPitch;
  <br /> 102
  <br /> 103 for (i = 0; i &lt; width; i++) {
  <br /> 104 ub = u_b_tab[*uoff];
  <br /> 105 ug = u_g_tab[*uoff];
  <br /> 106 vg = v_g_tab[*voff];
  <br /> 107 vr = v_r_tab[*voff];
  <br /> 108
  <br /> 109 b = RGB_V(*yoff + ub);
  <br /> 110 g = RGB_V(*yoff - ug - vg);
  <br /> 111 r = RGB_V(*yoff + vr);
  <br /> 112
  <br /> 113 *buffer = 0xff000000 | b &lt;&lt; 16 | g &lt;&lt; 8 | r;
  <br /> 114
  <br /> 115 buffer++;
  <br /> 116 yoff ++;
  <br /> 117
  <br /> 118 if ((i % 2) == 1) {
  <br /> 119 uoff++;
  <br /> 120 voff++;
  <br /> 121 }
  <br /> 122 }
  <br /> 123 }
  <br /> 124 }
  <br /> 125
  <br /> 126 int avc_decode_init(int width, int height)
  <br /> 127 {
  <br /> 128 if (fCodecContext != NULL) {
  <br /> 129 return 0;
  <br /> 130 }
  <br /> 131 avcodec_init();
  <br /> 132 avcodec_register_all();
  <br /> 133 fCodec = avcodec_find_decoder(CODEC_ID_H264);
  <br /> 134
  <br /> 135 fDisplayWidth = width;
  <br /> 136 fDisplayHeight = height;
  <br /> 137
  <br /> 138 CreateYUVTable();
  <br /> 139
  <br /> 140 fCodecContext = avcodec_alloc_context();
  <br /> 141 avcodec_open(fCodecContext, fCodec);
  <br /> 142 fVideoFrame = avcodec_alloc_frame();
  <br /> 143
  <br /> 144 return 1;
  <br /> 145 }
  <br /> 146
  <br /> 147 int avc_decode_release()
  <br /> 148 {
  <br /> 149 if (fCodecContext) {
  <br /> 150 avcodec_close(fCodecContext);
  <br /> 151 free(fCodecContext-&gt;priv_data);
  <br /> 152 free(fCodecContext);
  <br /> 153 fCodecContext = NULL;
  <br /> 154 }
  <br /> 155
  <br /> 156 if (fVideoFrame) {
  <br /> 157 free(fVideoFrame);
  <br /> 158 fVideoFrame = NULL;
  <br /> 159 }
  <br /> 160
  <br /> 161 DeleteYUVTable();
  <br /> 162 return 1;
  <br /> 163 }
  <br /> 164
  <br /> 165 int avc_decode(char* buf, int nalLen, char* out)
  <br /> 166 {
  <br /> 167 byte_t* data = (byte_t*)buf;
  <br /> 168 int frameSize = 0;
  <br /> 169
  <br /> 170 int ret = avcodec_decode_video(fCodecContext, fVideoFrame, &amp;frameSize, data, nalLen);
  <br /> 171 if (ret &lt;= 0) {
  <br /> 172 return ret;
  <br /> 173 }
  <br /> 174
  <br /> 175 int width = fCodecContext-&gt;width;
  <br /> 176 int height = fCodecContext-&gt;height;
  <br /> 177 DisplayYUV_32((uint32_t*)out, width, height, fDisplayWidth);
  <br /> 178 return ret;
  <br /> 179 }
 </div>
<p>&nbsp;</p></div><div id="MySignature"></div>
<div class="clear"></div>
<div id="blog_post_info_block">
<div id="blog_post_info">
</div>
<div class="clear"></div>
<div id="post_next_prev"></div>
</div>


		</div>
		<div class = "postDesc">posted @ <span id="post-date">2013-07-03 20:45</span> <a href='http://www.cnblogs.com/dyllove98/'>jlins</a> 阅读(<span id="post_view_count">...</span>) 评论(<span id="post_comment_count">...</span>)  <a href ="http://i.cnblogs.com/EditPosts.aspx?postid=3170295" rel="nofollow">编辑</a> <a href="#" onclick="AddToWz(3170295);return false;">收藏</a></div>
	</div>
	<script type="text/javascript">var allowComments=true,isLogined=false,cb_blogId=114118,cb_entryId=3170295,cb_blogApp=currentBlogApp,cb_blogUserGuid='1fe07a7d-6880-e111-aa3f-842b2b196315',cb_entryCreatedDate='2013/7/3 20:45:00';loadViewCount(cb_entryId);</script>
	
</div><!--end: topics 文章、评论容器-->
<a name="!comments"></a><div id="blog-comments-placeholder"></div><script type="text/javascript">var commentManager = new blogCommentManager();commentManager.renderComments(0);</script>
<div id="comment_form" class="commentform">
<a name="commentform"></a>
<div id="divCommentShow"></div>
<div id="comment_nav"><span id="span_refresh_tips"></span><a href="javascript:void(0);" id="lnk_RefreshComments" onclick="return RefreshCommentList();">刷新评论</a><a href="#" onclick="return RefreshPage();">刷新页面</a><a href="#top">返回顶部</a></div>
<div id="comment_form_container"></div>
<div class="ad_text_commentbox" id="ad_text_under_commentbox"></div>
<div id="site_nav_under"><a href="http://www.cnblogs.com/" target="_blank" title="程序员的网上家园">博客园首页</a><a href="http://q.cnblogs.com/" target="_blank" title="程序员问答社区">博问</a><a href="http://news.cnblogs.com/" target="_blank" title="IT新闻">新闻</a><a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a><a href="http://job.cnblogs.com/" target="_blank">程序员招聘</a><a href="http://kb.cnblogs.com/" target="_blank">知识库</a></div>
<div id="ad_under_post_holder"></div>
<script type="text/javascript">
var enableGoogleAd = true;
var googletag = googletag || {};
googletag.cmd = googletag.cmd || [];
fixPostBodyFormat();
loadAdUnderPost();
</script>
<div id="HistoryToday" class="c_ad_block"></div>
<script type="text/javascript">
loadBlogSignature();
LoadPostInfoBlock(cb_blogId, cb_entryId, cb_blogApp, cb_blogUserGuid);
GetPrevNextPost(cb_entryId, cb_blogId, cb_entryCreatedDate);
GetHistoryToday(cb_blogId, cb_blogApp, cb_entryCreatedDate);
</script>
<script type="text/javascript">
    $.ajax({ url: 'http://counter.cnblogs.com/blog/post/' + cb_entryId, type: 'get', dataType: 'script', cache: true });
</script>
</div>

	</div><!--end: forFlow -->
	</div><!--end: mainContent 主体内容容器-->

	<div id="sideBar">
		<div id="sideBarMain">
			
<!--done-->
<div class="newsItem">
<h3 class="catListTitle">公告</h3>
	<div id="blog-news"></div><script type="text/javascript">loadBlogNews();</script>
</div>

			<div id="blog-calendar" style="display:none"></div><script type="text/javascript">loadBlogDefaultCalendar();</script>
			
			<div id="leftcontentcontainer">
				<div id="blog-sidecolumn"></div><script type="text/javascript">loadBlogSideColumn();</script>
			</div>
			
		</div><!--end: sideBarMain -->
	</div><!--end: sideBar 侧边栏容器 -->
	<div class="clear"></div>
	</div><!--end: main -->
	<div class="clear"></div>
	<div id="footer">
		
<!--done-->
Copyright &copy;2014 jlins
	</div><!--end: footer -->
</div><!--end: home 自定义的最大容器 -->
</body>
</html>
